{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "days_before_event = 3\n",
    "days_after_event = 3\n",
    "\n",
    "RTD_higher_than = -70\n",
    "voltage_lower_than = 200\n",
    "\n",
    "remove_from_date = '2017-11-01'\n",
    "remove_until_date = '2018-08-01'\n",
    "\n",
    "# List of error events that indicate a problem in the freezer\n",
    "error_events = [\n",
    "    \"setpoint_change\",                     # Wrong setpoint\n",
    "    \"Bad insulation\",                      # Bad insulation\n",
    "    \"door_adjustment\",                     # Door tightness\n",
    "    \"High condensation water\",             # High condensation\n",
    "    \"display\",                             # Data missing\n",
    "    \"instability\",                         # Unstable operation\n",
    "    \"compressor_stage_1 malfunctional\",    # 1st stage compressor\n",
    "    \"compressor_stage_2 malfunctional\",    # 2nd stage compressor\n",
    "    \"electric_wiring\",                     # Electrical malfunction\n",
    "    \"Refrigerant leakage at stage 1\",      # Refrigerant leakage at stage 1\n",
    "    \"Refrigerant leakage at stage 2\"       # Refrigerant leakage at stage 2\n",
    "]\n",
    "\n",
    "\n",
    "# Path to the directory containing freezer data\n",
    "path = '/Users/muhammadhussain/Desktop/Data/Revco/'  # Replace with the actual path to your dataset\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_name in os.listdir(path):\n",
    "    # Check if the file matches the expected format\n",
    "    if file_name.endswith('_temp.parquet'):\n",
    "        # Extract the freezer number from the file name\n",
    "        Freezer_number = file_name.split('_')[0]\n",
    "        \n",
    "        # Load the Parquet file\n",
    "        df = pd.read_parquet(os.path.join(path, file_name))\n",
    "        \n",
    "        # Check if 'main_fault' column exists\n",
    "        if 'main_fault' not in df.columns:\n",
    "            print(f\"'main_fault' column not found in {file_name}, skipping...\")\n",
    "            continue  # Skip this file and move to the next\n",
    "        \n",
    "        # Ensure 'Datetime' is in datetime format\n",
    "        df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "        \n",
    "        # **Step 1**: Filter out rows based on `RTD` and `Mains Voltage`\n",
    "        df = df[(df['RTD'] <= RTD_higher_than) & (df['Mains Voltage'] >= voltage_lower_than)]\n",
    "        \n",
    "        # **Step 2**: Remove rows between dates (if needed)\n",
    "        # df = df[~((df['Datetime'] >= remove_from_date) & (df['Datetime'] <= remove_until_date))]\n",
    "        \n",
    "        # **Step 3**: Identify the indices where a main fault has occurred\n",
    "        fault_indices = df[df['main_fault'].notnull()].index\n",
    "        \n",
    "        # Sets to collect indices for rows to keep in the time window\n",
    "        indices_to_collect_error = set()\n",
    "        indices_to_collect_non_error = set()\n",
    "        \n",
    "        # Loop through each main fault\n",
    "        for idx in fault_indices:\n",
    "            # Get the main fault timestamp and fault value\n",
    "            fault_time = df.loc[idx, 'Datetime']\n",
    "            fault_value = df.loc[idx, 'main_fault']  # Get the fault value at the current index\n",
    "            \n",
    "            # Define the time window around the main fault\n",
    "            start_time = fault_time - pd.Timedelta(days=days_before_event)\n",
    "            end_time = fault_time + pd.Timedelta(days=days_after_event)\n",
    "            \n",
    "            # Select rows within the time window\n",
    "            mask = (df['Datetime'] >= start_time) & (df['Datetime'] <= end_time)\n",
    "            window_indices = df[mask].index\n",
    "            \n",
    "            # Check if the main fault is an error event\n",
    "            if fault_value in error_events:\n",
    "                indices_to_collect_error.update(window_indices)\n",
    "                \n",
    "                # Update the 'main_fault' column for all rows in this time window\n",
    "                df.loc[window_indices, 'main_fault'] = fault_value\n",
    "            else:\n",
    "                indices_to_collect_non_error.update(window_indices)\n",
    "        \n",
    "        # Create DataFrames for error events and clean data\n",
    "        df_around_events = df.loc[list(indices_to_collect_error)].copy()  # Data with error events in the time window\n",
    "        df_cleaned = df.drop(indices_to_collect_error.union(indices_to_collect_non_error))  # Remove all handled rows from main DataFrame\n",
    "        \n",
    "        # **Step 6**: Save both DataFrames\n",
    "        df_around_events.to_parquet(\n",
    "            os.path.join('/Users/muhammadhussain/Desktop/Data/filter/', f'around_events_data_{Freezer_number}.parquet'), index=False\n",
    "        )\n",
    "        df_cleaned.to_parquet(\n",
    "            os.path.join('/Users/muhammadhussain/Desktop/Data/filter/', f'cleaned_data_{Freezer_number}.parquet'), index=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "def process_parquet_files(path, output_file, window_size=60):\n",
    "    start_time = time.time()  # Track total time\n",
    "\n",
    "    # Modelnumre, der skal ekskluderes\n",
    "    excluded_models = {\"806026\", \"806030\", \"806031\", \"806276\", \"806279\"}\n",
    "\n",
    "    # Step 1: Load all parquet files matching the pattern\n",
    "    all_files = glob.glob(path + \"around_events_data_*.parquet\")\n",
    "    if not all_files:\n",
    "        print(f\"No files found in the directory {path}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Initialize a list to store processed windows\n",
    "    time_windows = []\n",
    "    total_groups = 0  # Counter for total number of groups across all models\n",
    "    skipped_groups_total = 0  # Counter for total skipped groups across all models\n",
    "\n",
    "    # Step 3: Process each file\n",
    "    for file in all_files:\n",
    "        # Extract the model number from the file name\n",
    "        model_number = os.path.basename(file).split('_')[3].split('.')[0]\n",
    "\n",
    "        # Check if the model number is in the excluded list\n",
    "        if model_number in excluded_models:\n",
    "            print(f\"Skipping model {model_number} (excluded)\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_parquet(file)\n",
    "        df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "        # Ensure the data is sorted by time\n",
    "        df = df.sort_values('Datetime').reset_index(drop=True)\n",
    "\n",
    "        # Step 4: Identify continuous sequences\n",
    "        df['time_diff'] = df['Datetime'].diff().dt.total_seconds()\n",
    "        df['is_continuous'] = (df['time_diff'].between(59, 61)) | (df.index == 0)\n",
    "        df['sequence_group'] = (~df['is_continuous']).cumsum()\n",
    "\n",
    "        # Step 5: Count total groups and filter valid sequences\n",
    "        groups = df.groupby('sequence_group')\n",
    "        total_groups += len(groups)  # Add total number of groups for this model\n",
    "        valid_sequences = groups.filter(lambda x: len(x) >= window_size)\n",
    "        skipped_groups_for_model = len(groups) - len(valid_sequences.groupby('sequence_group'))\n",
    "        skipped_groups_total += skipped_groups_for_model  # Add skipped groups for this model\n",
    "\n",
    "        # Step 6: Create time-windowed data\n",
    "        def process_group(group):\n",
    "            group_windows = []\n",
    "            for start_idx in range(0, len(group) - window_size + 1):\n",
    "                window = group.iloc[start_idx:start_idx + window_size]\n",
    "\n",
    "                # Flatten the window\n",
    "                flattened_window = {}\n",
    "                for column in window.columns:\n",
    "                    # Exclude 'main_fault' from being flattened\n",
    "                    if column not in ['Datetime', 'time_diff', 'is_continuous', 'sequence_group', 'main_fault']:\n",
    "                        if pd.api.types.is_numeric_dtype(window[column]):\n",
    "                            flattened_window.update({f\"{column}_{i}\": v for i, v in enumerate(window[column].tolist())})\n",
    "                        else:\n",
    "                            flattened_window.update({f\"{column}_0\": window[column].iloc[0]})  # Only take the first non-numeric value\n",
    "\n",
    "                # Add the latest Datetime in the window\n",
    "                flattened_window[\"Datetime\"] = window['Datetime'].iloc[-1]\n",
    "\n",
    "                # Add metadata\n",
    "                flattened_window[\"main_fault\"] = window['main_fault'].mode()[0] if not window['main_fault'].isna().all() else None\n",
    "                flattened_window[\"seriesnumber\"] = model_number\n",
    "                group_windows.append(flattened_window)\n",
    "\n",
    "            return group_windows\n",
    "\n",
    "        # Process each sequence group sequentially\n",
    "        valid_groups = [group for _, group in valid_sequences.groupby('sequence_group')]\n",
    "\n",
    "        print(f\"Processing {len(valid_groups)} valid groups for model {model_number}...\")\n",
    "        print(f\"Skipped groups for model {model_number}: {skipped_groups_for_model}\")\n",
    "\n",
    "        for group in valid_groups:\n",
    "            time_windows.extend(process_group(group))\n",
    "\n",
    "    print(f\"Total groups across all models: {total_groups}\")\n",
    "    print(f\"Total skipped groups across all models: {skipped_groups_total}\")\n",
    "\n",
    "    # Combine all flattened windows into a single DataFrame\n",
    "    all_data = pd.DataFrame(time_windows)\n",
    "\n",
    "    # Step 7: Normalize numeric columns\n",
    "    scaler = MinMaxScaler()\n",
    "    numeric_columns = all_data.select_dtypes(include=['number']).columns\n",
    "    if not numeric_columns.empty:\n",
    "        all_data[numeric_columns] = scaler.fit_transform(all_data[numeric_columns])\n",
    "\n",
    "    # Step 8: Save the prepared data\n",
    "    all_data.to_parquet(output_file, index=False)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Total elapsed time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping model 806031 (excluded)\n",
      "Processing 0 valid groups for model 806272...\n",
      "Skipped groups for model 806272: 0\n",
      "Processing 8 valid groups for model 806017...\n",
      "Skipped groups for model 806017: 6\n",
      "Processing 0 valid groups for model 806029...\n",
      "Skipped groups for model 806029: 0\n",
      "Processing 5 valid groups for model 806020...\n",
      "Skipped groups for model 806020: 4\n",
      "Skipping model 806030 (excluded)\n",
      "Processing 0 valid groups for model 806273...\n",
      "Skipped groups for model 806273: 0\n",
      "Processing 5 valid groups for model 806278...\n",
      "Skipped groups for model 806278: 4\n",
      "Processing 0 valid groups for model 806023...\n",
      "Skipped groups for model 806023: 0\n",
      "Processing 0 valid groups for model 806033...\n",
      "Skipped groups for model 806033: 0\n",
      "Skipping model 806279 (excluded)\n",
      "Processing 0 valid groups for model 806269...\n",
      "Skipped groups for model 806269: 0\n",
      "Processing 0 valid groups for model 808301...\n",
      "Skipped groups for model 808301: 0\n",
      "Processing 0 valid groups for model 806265...\n",
      "Skipped groups for model 806265: 0\n",
      "Skipping model 806026 (excluded)\n",
      "Processing 0 valid groups for model 806281...\n",
      "Skipped groups for model 806281: 0\n",
      "Processing 2 valid groups for model 806274...\n",
      "Skipped groups for model 806274: 1\n",
      "Processing 3 valid groups for model 806018...\n",
      "Skipped groups for model 806018: 12\n",
      "Skipping model 806276 (excluded)\n",
      "Processing 0 valid groups for model 806282...\n",
      "Skipped groups for model 806282: 0\n",
      "Processing 0 valid groups for model 808783...\n",
      "Skipped groups for model 808783: 0\n",
      "Processing 8 valid groups for model 806277...\n",
      "Skipped groups for model 806277: 5\n",
      "Processing 0 valid groups for model 806024...\n",
      "Skipped groups for model 806024: 0\n",
      "Processing 0 valid groups for model 806283...\n",
      "Skipped groups for model 806283: 0\n",
      "Total groups across all models: 63\n",
      "Total skipped groups across all models: 32\n",
      "Total elapsed time: 82.99 seconds\n"
     ]
    }
   ],
   "source": [
    "# Angiv sti til dine data og output-fil\n",
    "path = \"/Users/muhammadhussain/Desktop/Data/filter/\"\n",
    "output_file = \"/Users/muhammadhussain/Desktop/Data/filter/finished.parquet\"\n",
    "\n",
    "# Kald funktionen\n",
    "process_parquet_files(path, output_file, window_size=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>RTD</th>\n",
       "      <th>1st Suc.</th>\n",
       "      <th>Cond. Air In</th>\n",
       "      <th>Evap. In</th>\n",
       "      <th>Evap. Out</th>\n",
       "      <th>2nd Suc.</th>\n",
       "      <th>Chil. water In</th>\n",
       "      <th>2nd Sump</th>\n",
       "      <th>H.E.</th>\n",
       "      <th>SetPoint</th>\n",
       "      <th>Mains Voltage</th>\n",
       "      <th>State</th>\n",
       "      <th>Type</th>\n",
       "      <th>Event</th>\n",
       "      <th>main_fault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Datetime, RTD, 1st Suc., Cond. Air In, Evap. In, Evap. Out, 2nd Suc., Chil. water In, 2nd Sump, H.E., SetPoint, Mains Voltage, State, Type, Event, main_fault]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('/Users/muhammadhussain/Desktop/Data/filter/around_events_data_806031.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 'relay', 'compressor_stage_2'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('/Users/muhammadhussain/Desktop/Data/Revco/806269_temp.parquet')[\"main_fault\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RTD_0</th>\n",
       "      <th>RTD_1</th>\n",
       "      <th>RTD_2</th>\n",
       "      <th>RTD_3</th>\n",
       "      <th>RTD_4</th>\n",
       "      <th>RTD_5</th>\n",
       "      <th>RTD_6</th>\n",
       "      <th>RTD_7</th>\n",
       "      <th>RTD_8</th>\n",
       "      <th>RTD_9</th>\n",
       "      <th>...</th>\n",
       "      <th>State_55</th>\n",
       "      <th>State_56</th>\n",
       "      <th>State_57</th>\n",
       "      <th>State_58</th>\n",
       "      <th>State_59</th>\n",
       "      <th>Type_0</th>\n",
       "      <th>Event_0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>main_fault</th>\n",
       "      <th>seriesnumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.198198</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-03-16 12:59:12</td>\n",
       "      <td>Refrigerant leakage at stage 1</td>\n",
       "      <td>806017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-03-16 13:00:12</td>\n",
       "      <td>Refrigerant leakage at stage 1</td>\n",
       "      <td>806017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205357</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-03-16 13:01:12</td>\n",
       "      <td>Refrigerant leakage at stage 1</td>\n",
       "      <td>806017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205357</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-03-16 13:02:12</td>\n",
       "      <td>Refrigerant leakage at stage 1</td>\n",
       "      <td>806017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.205357</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-03-16 13:03:12</td>\n",
       "      <td>Refrigerant leakage at stage 1</td>\n",
       "      <td>806017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59120</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.072072</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-10-27 11:55:41</td>\n",
       "      <td>instability</td>\n",
       "      <td>806277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59121</th>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.072072</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-10-27 11:56:41</td>\n",
       "      <td>instability</td>\n",
       "      <td>806277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59122</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>0.198198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-10-27 11:57:41</td>\n",
       "      <td>instability</td>\n",
       "      <td>806277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59123</th>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>0.198198</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-10-27 11:58:41</td>\n",
       "      <td>instability</td>\n",
       "      <td>806277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59124</th>\n",
       "      <td>0.080357</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>0.198198</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-10-27 11:59:41</td>\n",
       "      <td>instability</td>\n",
       "      <td>806277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59125 rows Ã— 725 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RTD_0     RTD_1     RTD_2     RTD_3     RTD_4     RTD_5     RTD_6  \\\n",
       "0      0.187500  0.198198  0.207207  0.207207  0.207207  0.207207  0.216216   \n",
       "1      0.196429  0.207207  0.207207  0.207207  0.207207  0.216216  0.216216   \n",
       "2      0.205357  0.207207  0.207207  0.207207  0.216216  0.216216  0.207207   \n",
       "3      0.205357  0.207207  0.207207  0.216216  0.216216  0.207207  0.189189   \n",
       "4      0.205357  0.207207  0.216216  0.216216  0.207207  0.189189  0.153153   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "59120  0.035714  0.054054  0.072072  0.090090  0.081081  0.126126  0.144144   \n",
       "59121  0.053571  0.072072  0.090090  0.081081  0.126126  0.144144  0.153153   \n",
       "59122  0.071429  0.090090  0.081081  0.126126  0.144144  0.153153  0.171171   \n",
       "59123  0.089286  0.081081  0.126126  0.144144  0.153153  0.171171  0.180180   \n",
       "59124  0.080357  0.126126  0.144144  0.153153  0.171171  0.180180  0.180180   \n",
       "\n",
       "          RTD_7     RTD_8     RTD_9  ...  State_55  State_56  State_57  \\\n",
       "0      0.216216  0.207207  0.189189  ...  0.157895  0.157895  0.157895   \n",
       "1      0.207207  0.189189  0.153153  ...  0.157895  0.157895  0.157895   \n",
       "2      0.189189  0.153153  0.081081  ...  0.157895  0.157895  0.157895   \n",
       "3      0.153153  0.081081  0.036036  ...  0.157895  0.157895  0.157895   \n",
       "4      0.081081  0.036036  0.018018  ...  0.157895  0.157895  0.052632   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "59120  0.153153  0.171171  0.180180  ...  0.157895  0.157895  0.157895   \n",
       "59121  0.171171  0.180180  0.180180  ...  0.157895  0.157895  0.157895   \n",
       "59122  0.180180  0.180180  0.198198  ...  0.157895  0.157895  0.157895   \n",
       "59123  0.180180  0.198198  0.207207  ...  0.157895  0.157895  0.157895   \n",
       "59124  0.198198  0.207207  0.207207  ...  0.157895  0.157895  0.157895   \n",
       "\n",
       "       State_58  State_59  Type_0  Event_0            Datetime  \\\n",
       "0      0.157895  0.157895    None     None 2015-03-16 12:59:12   \n",
       "1      0.157895  0.157895    None     None 2015-03-16 13:00:12   \n",
       "2      0.157895  0.052632    None     None 2015-03-16 13:01:12   \n",
       "3      0.052632  0.000000    None     None 2015-03-16 13:02:12   \n",
       "4      0.000000  0.000000    None     None 2015-03-16 13:03:12   \n",
       "...         ...       ...     ...      ...                 ...   \n",
       "59120  0.157895  0.157895    None     None 2022-10-27 11:55:41   \n",
       "59121  0.157895  0.157895    None     None 2022-10-27 11:56:41   \n",
       "59122  0.157895  0.157895    None     None 2022-10-27 11:57:41   \n",
       "59123  0.157895  0.157895    None     None 2022-10-27 11:58:41   \n",
       "59124  0.157895  0.157895    None     None 2022-10-27 11:59:41   \n",
       "\n",
       "                           main_fault  seriesnumber  \n",
       "0      Refrigerant leakage at stage 1        806017  \n",
       "1      Refrigerant leakage at stage 1        806017  \n",
       "2      Refrigerant leakage at stage 1        806017  \n",
       "3      Refrigerant leakage at stage 1        806017  \n",
       "4      Refrigerant leakage at stage 1        806017  \n",
       "...                               ...           ...  \n",
       "59120                     instability        806277  \n",
       "59121                     instability        806277  \n",
       "59122                     instability        806277  \n",
       "59123                     instability        806277  \n",
       "59124                     instability        806277  \n",
       "\n",
       "[59125 rows x 725 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"/Users/muhammadhussain/Desktop/Data/filter/finished.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique 'main_fault' values: 23\n",
      "Unique values: {'main_board', 'setpoint_change', 'Refrigerant leakage at stage 2', 'fuse_blown', 'warm_alarm', 'door_adjustment', 'display', 'filter_drier', 'relay', 'battery', 'compressor_stage_2 malfunctional', 'logic_wiring', 'OS_update', 'instability', 'warm_interstage', 'compressor_stage_2', 'High condensation water', 'water_control_valve', 'electric_wiring', 'Refrigerant leakage at stage 1', 'compressor_stage_1', 'compressor_stage_1 malfunctional', 'handle_tightening'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = \"/Users/muhammadhussain/Desktop/Data/Revco/\"\n",
    "\n",
    "# Initialize a set to store unique values of 'main_fault'\n",
    "unique_main_faults = set()\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_name in os.listdir(directory_path):\n",
    "    # Check if the file is a Parquet file\n",
    "    if file_name.endswith(\".parquet\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        try:\n",
    "            # Load the Parquet file\n",
    "            df = pd.read_parquet(file_path)\n",
    "            \n",
    "            # Check if the 'main_fault' column exists\n",
    "            if 'main_fault' in df.columns:\n",
    "                # Add unique values from the 'main_fault' column to the set\n",
    "                unique_main_faults.update(df['main_fault'].dropna().unique())\n",
    "        except Exception as e:\n",
    "            print(f\"Could not process file {file_name}: {e}\")\n",
    "\n",
    "# Display the total number of unique values\n",
    "print(f\"Total unique 'main_fault' values: {len(unique_main_faults)}\")\n",
    "print(f\"Unique values: {unique_main_faults}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[neuralnetwork]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
