{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'main_fault' column not found in 806275_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806267_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806027_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806280_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806016_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806034_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806021_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806830_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806268_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806019_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806270_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806028_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806271_temp.parquet, skipping...\n",
      "'main_fault' column not found in 806829_temp.parquet, skipping...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "days_before_event = 3\n",
    "days_after_event = 3\n",
    "\n",
    "RTD_higher_than = -70\n",
    "voltage_lower_than = 200\n",
    "\n",
    "remove_from_date = '2017-11-01'\n",
    "remove_until_date = '2018-08-01'\n",
    "\n",
    "# List of error events that indicate a problem in the freezer\n",
    "error_events = [\n",
    "    \"setpoint_change\",                     # Wrong setpoint\n",
    "    \"Bad insulation\",                      # Bad insulation\n",
    "    \"door_adjustment\",                     # Door tightness\n",
    "    \"High condensation water\",             # High condensation\n",
    "    \"display\",                             # Data missing\n",
    "    \"instability\",                         # Unstable operation\n",
    "    \"compressor_stage_1 malfunctional\",    # 1st stage compressor\n",
    "    \"compressor_stage_2 malfunctional\",    # 2nd stage compressor\n",
    "    \"electric_wiring\",                     # Electrical malfunction\n",
    "    \"Refrigerant leakage at stage 1\",      # Refrigerant leakage\n",
    "    \"Refrigerant leakage at stage 2\"\n",
    "]\n",
    "\n",
    "# Path to the directory containing freezer data\n",
    "path = '/Users/muhammadhussain/Desktop/Data/Revco/'  # Replace with the actual path to your dataset\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_name in os.listdir(path):\n",
    "    # Check if the file matches the expected format\n",
    "    if file_name.endswith('_temp.parquet'):\n",
    "        # Extract the freezer number from the file name\n",
    "        Freezer_number = file_name.split('_')[0]\n",
    "        \n",
    "        # Load the Parquet file\n",
    "        df = pd.read_parquet(os.path.join(path, file_name))\n",
    "        \n",
    "        # Check if 'main_fault' column exists\n",
    "        if 'main_fault' not in df.columns:\n",
    "            print(f\"'main_fault' column not found in {file_name}, skipping...\")\n",
    "            continue  # Skip this file and move to the next\n",
    "        \n",
    "        # Ensure 'Datetime' is in datetime format\n",
    "        df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "        \n",
    "        # **Step 1**: Filter out rows based on `RTD` and `Mains Voltage`\n",
    "        df = df[(df['RTD'] <= RTD_higher_than) & (df['Mains Voltage'] >= voltage_lower_than)]\n",
    "        \n",
    "        # **Step 2**: Remove rows between dates (if needed)\n",
    "        # df = df[~((df['Datetime'] >= remove_from_date) & (df['Datetime'] <= remove_until_date))]\n",
    "        \n",
    "        # **Step 3**: Identify the indices where a main fault has occurred\n",
    "        fault_indices = df[df['main_fault'].notnull()].index\n",
    "        \n",
    "        # Sets to collect indices for rows to keep in the time window\n",
    "        indices_to_collect_error = set()\n",
    "        indices_to_collect_non_error = set()\n",
    "        \n",
    "        # Loop through each main fault\n",
    "        for idx in fault_indices:\n",
    "            # Get the main fault timestamp and fault value\n",
    "            fault_time = df.loc[idx, 'Datetime']\n",
    "            fault_value = df.loc[idx, 'main_fault']  # Get the fault value at the current index\n",
    "            \n",
    "            # Define the time window around the main fault\n",
    "            start_time = fault_time - pd.Timedelta(days=days_before_event)\n",
    "            end_time = fault_time + pd.Timedelta(days=days_after_event)\n",
    "            \n",
    "            # Select rows within the time window\n",
    "            mask = (df['Datetime'] >= start_time) & (df['Datetime'] <= end_time)\n",
    "            window_indices = df[mask].index\n",
    "            \n",
    "            # Check if the main fault is an error event\n",
    "            if fault_value in error_events:\n",
    "                # Assign the same main_fault value to all rows in the window\n",
    "                df.loc[window_indices, 'main_fault'] = fault_value\n",
    "                indices_to_collect_error.update(window_indices)\n",
    "            else:\n",
    "                indices_to_collect_non_error.update(window_indices)\n",
    "        \n",
    "        # Create DataFrames for error events and clean data\n",
    "        df_around_events = df.loc[list(indices_to_collect_error)].copy()  # Data with error events in the time window\n",
    "        df_cleaned = df.drop(indices_to_collect_error.union(indices_to_collect_non_error))  # Remove all handled rows from main DataFrame\n",
    "        \n",
    "        # **Step 6**: Save both DataFrames\n",
    "        df_around_events.to_parquet(\n",
    "            os.path.join('/Users/muhammadhussain/Desktop/Data/filter/', f'around_events_data_{Freezer_number}.parquet'), index=False\n",
    "        )\n",
    "        df_cleaned.to_parquet(\n",
    "            os.path.join('/Users/muhammadhussain/Desktop/Data/filter/', f'cleaned_data_{Freezer_number}.parquet'), index=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "path = '/Users/muhammadhussain/Desktop/Data/filter/'\n",
    "\n",
    "def process_parquet_files(path, output_file, window_size=60):\n",
    "    start_time = time.time()  # Track total time\n",
    "\n",
    "    # Modelnumre, der skal ekskluderes\n",
    "    excluded_models = {\"806026\", \"806030\", \"806031\", \"806276\", \"806279\"}\n",
    "\n",
    "    # Step 1: Load all parquet files matching the pattern\n",
    "    around_event_files = glob.glob(path + \"around_events_data_*.parquet\")\n",
    "    cleaned_data_file = os.path.join(path, \"cleaned_data_806278.parquet\")\n",
    "\n",
    "    if not around_event_files:\n",
    "        print(f\"No 'around_events_data_*' files found in the directory {path}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Initialize a list to store processed windows\n",
    "    time_windows = []\n",
    "    total_groups = 0  # Counter for total number of groups across all models\n",
    "    skipped_groups_total = 0  # Counter for total skipped groups across all models\n",
    "\n",
    "    # Step 3: Process \"around_events_data_*.parquet\" files\n",
    "    for file in around_event_files:\n",
    "        model_number = os.path.basename(file).split('_')[3].split('.')[0]\n",
    "\n",
    "        # Check if the model number is in the excluded list\n",
    "        if model_number in excluded_models:\n",
    "            print(f\"Skipping model {model_number} (excluded)\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_parquet(file)\n",
    "        df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "        # Ensure the data is sorted by time\n",
    "        df = df.sort_values('Datetime').reset_index(drop=True)\n",
    "\n",
    "        # Step 4: Identify continuous sequences\n",
    "        df['time_diff'] = df['Datetime'].diff().dt.total_seconds()\n",
    "        df['is_continuous'] = (df['time_diff'].between(59, 61)) | (df.index == 0)\n",
    "        df['sequence_group'] = (~df['is_continuous']).cumsum()\n",
    "\n",
    "        # Step 5: Count total groups and filter valid sequences\n",
    "        groups = df.groupby('sequence_group')\n",
    "        total_groups += len(groups)  # Add total number of groups for this model\n",
    "        valid_sequences = groups.filter(lambda x: len(x) >= window_size)\n",
    "        skipped_groups_for_model = len(groups) - len(valid_sequences.groupby('sequence_group'))\n",
    "        skipped_groups_total += skipped_groups_for_model\n",
    "\n",
    "        # Step 6: Create time-windowed data\n",
    "        def process_group(group):\n",
    "            group_windows = []\n",
    "            for start_idx in range(0, len(group) - window_size + 1):\n",
    "                window = group.iloc[start_idx:start_idx + window_size]\n",
    "\n",
    "                # Flatten the window\n",
    "                flattened_window = {}\n",
    "                for column in window.columns:\n",
    "                    if column not in ['Datetime', 'time_diff', 'is_continuous', 'sequence_group', 'main_fault']:\n",
    "                        if pd.api.types.is_numeric_dtype(window[column]):\n",
    "                            flattened_window.update({f\"{column}_{i}\": v for i, v in enumerate(window[column].tolist())})\n",
    "                        else:\n",
    "                            flattened_window.update({f\"{column}_0\": window[column].iloc[0]})  # Only take the first non-numeric value\n",
    "\n",
    "                # Add the latest Datetime in the window\n",
    "                flattened_window[\"Datetime\"] = window['Datetime'].iloc[-1]\n",
    "\n",
    "                # Add metadata\n",
    "                flattened_window[\"main_fault\"] = window['main_fault'].mode()[0] if not window['main_fault'].isna().all() else None\n",
    "                flattened_window[\"seriesnumber\"] = model_number\n",
    "                group_windows.append(flattened_window)\n",
    "\n",
    "            return group_windows\n",
    "\n",
    "        valid_groups = [group for _, group in valid_sequences.groupby('sequence_group')]\n",
    "        print(f\"Processing {len(valid_groups)} valid groups for model {model_number}...\")\n",
    "        print(f\"Skipped groups for model {model_number}: {skipped_groups_for_model}\")\n",
    "\n",
    "        for group in valid_groups:\n",
    "            time_windows.extend(process_group(group))\n",
    "\n",
    "    print(f\"Total groups across all models: {total_groups}\")\n",
    "    print(f\"Total skipped groups across all models: {skipped_groups_total}\")\n",
    "\n",
    "    # Step 4: Process \"cleaned_data_806278.parquet\" file\n",
    "    if os.path.exists(cleaned_data_file):\n",
    "        print(f\"Processing cleaned data from: {cleaned_data_file}\")\n",
    "        df_cleaned = pd.read_parquet(cleaned_data_file)\n",
    "        df_cleaned['Datetime'] = pd.to_datetime(df_cleaned['Datetime'])\n",
    "        df_cleaned = df_cleaned.sort_values('Datetime').reset_index(drop=True)\n",
    "\n",
    "        # Identify continuous sequences\n",
    "        df_cleaned['time_diff'] = df_cleaned['Datetime'].diff().dt.total_seconds()\n",
    "        df_cleaned['is_continuous'] = (df_cleaned['time_diff'].between(59, 61)) | (df_cleaned.index == 0)\n",
    "        df_cleaned['sequence_group'] = (~df_cleaned['is_continuous']).cumsum()\n",
    "\n",
    "        # Determine how many rows to include (10% of the total from time_windows)\n",
    "        limit = int(len(time_windows) * 0.1)\n",
    "\n",
    "        # Select rows up to the limit\n",
    "        cleaned_windows = []\n",
    "        for _, group in df_cleaned.groupby('sequence_group'):\n",
    "            if len(group) >= window_size:\n",
    "                for start_idx in range(0, len(group) - window_size + 1):\n",
    "                    window = group.iloc[start_idx:start_idx + window_size]\n",
    "\n",
    "                    # Flatten the window\n",
    "                    flattened_window = {}\n",
    "                    for column in window.columns:\n",
    "                        if column not in ['Datetime', 'time_diff', 'is_continuous', 'sequence_group']:\n",
    "                            if pd.api.types.is_numeric_dtype(window[column]):\n",
    "                                flattened_window.update({f\"{column}_{i}\": v for i, v in enumerate(window[column].tolist())})\n",
    "                            else:\n",
    "                                flattened_window.update({f\"{column}_0\": window[column].iloc[0]})\n",
    "\n",
    "                    # Add the latest Datetime in the window\n",
    "                    flattened_window[\"Datetime\"] = window['Datetime'].iloc[-1]\n",
    "                    flattened_window[\"main_fault\"] = None  # Always None for cleaned data\n",
    "                    flattened_window[\"seriesnumber\"] = \"806278\"\n",
    "                    cleaned_windows.append(flattened_window)\n",
    "\n",
    "                    # Stop if we've reached the limit\n",
    "                    if len(cleaned_windows) >= limit:\n",
    "                        break\n",
    "            if len(cleaned_windows) >= limit:\n",
    "                break\n",
    "        print(f\"Added {len(cleaned_windows)} rows from cleaned data.\")\n",
    "        time_windows.extend(cleaned_windows)\n",
    "\n",
    "    # Combine all flattened windows into a single DataFrame\n",
    "    all_data = pd.DataFrame(time_windows)\n",
    "\n",
    "    # Step 7: Normalize numeric columns\n",
    "    scaler = MinMaxScaler()\n",
    "    numeric_columns = all_data.select_dtypes(include=['number']).columns\n",
    "    if not numeric_columns.empty:\n",
    "        all_data[numeric_columns] = scaler.fit_transform(all_data[numeric_columns])\n",
    "\n",
    "    # Step 8: Save the prepared data\n",
    "    all_data.to_parquet(output_file, index=False)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Total elapsed time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>RTD</th>\n",
       "      <th>1st Suc.</th>\n",
       "      <th>Cond. Air In</th>\n",
       "      <th>Evap. In</th>\n",
       "      <th>Evap. Out</th>\n",
       "      <th>2nd Suc.</th>\n",
       "      <th>Chil. water In</th>\n",
       "      <th>2nd Sump</th>\n",
       "      <th>H.E.</th>\n",
       "      <th>SetPoint</th>\n",
       "      <th>Mains Voltage</th>\n",
       "      <th>State</th>\n",
       "      <th>Type</th>\n",
       "      <th>Event</th>\n",
       "      <th>main_fault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-06 23:10:13</td>\n",
       "      <td>-70.5</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>-85.1</td>\n",
       "      <td>-74.4</td>\n",
       "      <td>-26.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>51.9</td>\n",
       "      <td>-40.3</td>\n",
       "      <td>-80</td>\n",
       "      <td>231.2</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-06 23:11:13</td>\n",
       "      <td>-71.8</td>\n",
       "      <td>-12.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>-75.7</td>\n",
       "      <td>-27.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>51.7</td>\n",
       "      <td>-40.2</td>\n",
       "      <td>-80</td>\n",
       "      <td>231.7</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-06 23:12:13</td>\n",
       "      <td>-73.9</td>\n",
       "      <td>-12.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-84.9</td>\n",
       "      <td>-77.8</td>\n",
       "      <td>-27.6</td>\n",
       "      <td>17.7</td>\n",
       "      <td>51.5</td>\n",
       "      <td>-39.9</td>\n",
       "      <td>-80</td>\n",
       "      <td>231.1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-03-06 23:13:13</td>\n",
       "      <td>-74.7</td>\n",
       "      <td>-12.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>-84.9</td>\n",
       "      <td>-81.5</td>\n",
       "      <td>-28.2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>51.5</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>-80</td>\n",
       "      <td>231.2</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-03-06 23:14:13</td>\n",
       "      <td>-76.3</td>\n",
       "      <td>-12.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>-84.9</td>\n",
       "      <td>-84.1</td>\n",
       "      <td>-28.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>51.4</td>\n",
       "      <td>-39.5</td>\n",
       "      <td>-80</td>\n",
       "      <td>231.4</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2017-03-07 10:25:13</td>\n",
       "      <td>-80.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>14.7</td>\n",
       "      <td>-69.7</td>\n",
       "      <td>-82.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>32.6</td>\n",
       "      <td>-27.6</td>\n",
       "      <td>-80</td>\n",
       "      <td>232.6</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2017-03-07 10:26:13</td>\n",
       "      <td>-79.7</td>\n",
       "      <td>-34.5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>-69.6</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>31.4</td>\n",
       "      <td>-44.7</td>\n",
       "      <td>-80</td>\n",
       "      <td>229.1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2017-03-07 10:27:13</td>\n",
       "      <td>-79.4</td>\n",
       "      <td>-39.5</td>\n",
       "      <td>15.1</td>\n",
       "      <td>-77.3</td>\n",
       "      <td>-83.2</td>\n",
       "      <td>-32.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>29.2</td>\n",
       "      <td>-39.7</td>\n",
       "      <td>-80</td>\n",
       "      <td>229.6</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2017-03-07 10:28:13</td>\n",
       "      <td>-79.3</td>\n",
       "      <td>-37.9</td>\n",
       "      <td>15.1</td>\n",
       "      <td>-81.7</td>\n",
       "      <td>-83.5</td>\n",
       "      <td>-46.9</td>\n",
       "      <td>17.1</td>\n",
       "      <td>27.3</td>\n",
       "      <td>-34.2</td>\n",
       "      <td>-80</td>\n",
       "      <td>229.2</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>2017-03-07 10:29:13</td>\n",
       "      <td>-79.2</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>-82.6</td>\n",
       "      <td>-82.9</td>\n",
       "      <td>-47.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>28.3</td>\n",
       "      <td>-31.6</td>\n",
       "      <td>-80</td>\n",
       "      <td>229.6</td>\n",
       "      <td>3</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[\"Shutdown\"]</td>\n",
       "      <td>Refrigerant leakage at stage 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Datetime   RTD  1st Suc.  Cond. Air In  Evap. In  Evap. Out  \\\n",
       "0   2017-03-06 23:10:13 -70.5     -12.8          15.9     -85.1      -74.4   \n",
       "1   2017-03-06 23:11:13 -71.8     -12.6          16.0     -85.0      -75.7   \n",
       "2   2017-03-06 23:12:13 -73.9     -12.6          16.0     -84.9      -77.8   \n",
       "3   2017-03-06 23:13:13 -74.7     -12.6          15.7     -84.9      -81.5   \n",
       "4   2017-03-06 23:14:13 -76.3     -12.6          15.8     -84.9      -84.1   \n",
       "..                  ...   ...       ...           ...       ...        ...   \n",
       "675 2017-03-07 10:25:13 -80.2      -3.3          14.7     -69.7      -82.2   \n",
       "676 2017-03-07 10:26:13 -79.7     -34.5          14.8     -69.6      -82.0   \n",
       "677 2017-03-07 10:27:13 -79.4     -39.5          15.1     -77.3      -83.2   \n",
       "678 2017-03-07 10:28:13 -79.3     -37.9          15.1     -81.7      -83.5   \n",
       "679 2017-03-07 10:29:13 -79.2     -30.0          15.2     -82.6      -82.9   \n",
       "\n",
       "     2nd Suc.  Chil. water In  2nd Sump  H.E.  SetPoint  Mains Voltage  State  \\\n",
       "0       -26.7            17.7      51.9 -40.3       -80          231.2      3   \n",
       "1       -27.3            17.7      51.7 -40.2       -80          231.7      3   \n",
       "2       -27.6            17.7      51.5 -39.9       -80          231.1      3   \n",
       "3       -28.2            17.7      51.5 -39.8       -80          231.2      3   \n",
       "4       -28.7            17.7      51.4 -39.5       -80          231.4      3   \n",
       "..        ...             ...       ...   ...       ...            ...    ...   \n",
       "675       4.2            15.2      32.6 -27.6       -80          232.6      1   \n",
       "676       3.1            16.9      31.4 -44.7       -80          229.1      3   \n",
       "677     -32.8            17.2      29.2 -39.7       -80          229.6      3   \n",
       "678     -46.9            17.1      27.3 -34.2       -80          229.2      3   \n",
       "679     -47.5            17.4      28.3 -31.6       -80          229.6      3   \n",
       "\n",
       "     Type         Event                      main_fault  \n",
       "0    None          None                            None  \n",
       "1    None          None                            None  \n",
       "2    None          None                            None  \n",
       "3    None          None                            None  \n",
       "4    None          None                            None  \n",
       "..    ...           ...                             ...  \n",
       "675  None          None                            None  \n",
       "676  None          None                            None  \n",
       "677  None          None                            None  \n",
       "678  None          None                            None  \n",
       "679  [46]  [\"Shutdown\"]  Refrigerant leakage at stage 1  \n",
       "\n",
       "[680 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"/Users/muhammadhussain/Desktop/Data/filter/around_events_data_806274.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Refrigerant leakage at stage 1', 'High condensation water',\n",
       "       'electric_wiring', 'compressor_stage_1 malfunctional',\n",
       "       'instability', None], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"/Users/muhammadhussain/Desktop/Data/filter/finished.parquet\")[\"main_fault\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[neuralnetwork]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
