{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "def process_parquet_files(path, output_file, window_size=60):\n",
    "    start_time = time.time()  # Track total time\n",
    "\n",
    "    # Modelnumre, der skal ekskluderes\n",
    "    excluded_models = {\"806026\", \"806030\", \"806031\", \"806276\", \"806279\"}\n",
    "\n",
    "    # Step 1: Load all parquet files matching the pattern\n",
    "    around_event_files = glob.glob(path + \"around_events_data_*.parquet\")\n",
    "    cleaned_data_file = os.path.join(path, \"cleaned_data_806278.parquet\")\n",
    "\n",
    "    if not around_event_files:\n",
    "        print(f\"No 'around_events_data_*' files found in the directory {path}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Initialize a list to store processed windows\n",
    "    time_windows = []\n",
    "    total_groups = 0  # Counter for total number of groups across all models\n",
    "    skipped_groups_total = 0  # Counter for total skipped groups across all models\n",
    "\n",
    "    # Step 3: Process \"around_events_data_*.parquet\" files\n",
    "    for file in around_event_files:\n",
    "        model_number = os.path.basename(file).split('_')[3].split('.')[0]\n",
    "\n",
    "        # Check if the model number is in the excluded list\n",
    "        if model_number in excluded_models:\n",
    "            print(f\"Skipping model {model_number} (excluded)\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_parquet(file)\n",
    "        df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "        # Ensure the data is sorted by time\n",
    "        df = df.sort_values('Datetime').reset_index(drop=True)\n",
    "\n",
    "        # Step 4: Identify continuous sequences\n",
    "        df['time_diff'] = df['Datetime'].diff().dt.total_seconds()\n",
    "        df['is_continuous'] = (df['time_diff'].between(59, 61)) | (df.index == 0)\n",
    "        df['sequence_group'] = (~df['is_continuous']).cumsum()\n",
    "\n",
    "        # Step 5: Count total groups and filter valid sequences\n",
    "        groups = df.groupby('sequence_group')\n",
    "        total_groups += len(groups)  # Add total number of groups for this model\n",
    "        valid_sequences = groups.filter(lambda x: len(x) >= window_size)\n",
    "        skipped_groups_for_model = len(groups) - len(valid_sequences.groupby('sequence_group'))\n",
    "        skipped_groups_total += skipped_groups_for_model\n",
    "\n",
    "        # Step 6: Create time-windowed data\n",
    "        def process_group(group):\n",
    "            group_windows = []\n",
    "            for start_idx in range(0, len(group) - window_size + 1):\n",
    "                window = group.iloc[start_idx:start_idx + window_size]\n",
    "\n",
    "                # Flatten the window\n",
    "                flattened_window = {}\n",
    "                for column in window.columns:\n",
    "                    if column not in ['Datetime', 'time_diff', 'is_continuous', 'sequence_group', 'main_fault']:\n",
    "                        if pd.api.types.is_numeric_dtype(window[column]):\n",
    "                            flattened_window.update({f\"{column}_{i}\": v for i, v in enumerate(window[column].tolist())})\n",
    "                        else:\n",
    "                            flattened_window.update({f\"{column}_0\": window[column].iloc[0]})  # Only take the first non-numeric value\n",
    "\n",
    "                # Add the latest Datetime in the window\n",
    "                flattened_window[\"Datetime\"] = window['Datetime'].iloc[-1]\n",
    "\n",
    "                # Add metadata\n",
    "                flattened_window[\"main_fault\"] = window['main_fault'].mode()[0] if not window['main_fault'].isna().all() else None\n",
    "                flattened_window[\"seriesnumber\"] = model_number\n",
    "                group_windows.append(flattened_window)\n",
    "\n",
    "            return group_windows\n",
    "\n",
    "        valid_groups = [group for _, group in valid_sequences.groupby('sequence_group')]\n",
    "        print(f\"Processing {len(valid_groups)} valid groups for model {model_number}...\")\n",
    "        print(f\"Skipped groups for model {model_number}: {skipped_groups_for_model}\")\n",
    "\n",
    "        for group in valid_groups:\n",
    "            time_windows.extend(process_group(group))\n",
    "\n",
    "    print(f\"Total groups across all models: {total_groups}\")\n",
    "    print(f\"Total skipped groups across all models: {skipped_groups_total}\")\n",
    "\n",
    "    # Step 4: Process \"cleaned_data_806278.parquet\" file\n",
    "    if os.path.exists(cleaned_data_file):\n",
    "        print(f\"Processing cleaned data from: {cleaned_data_file}\")\n",
    "        df_cleaned = pd.read_parquet(cleaned_data_file)\n",
    "        df_cleaned['Datetime'] = pd.to_datetime(df_cleaned['Datetime'])\n",
    "        df_cleaned = df_cleaned.sort_values('Datetime').reset_index(drop=True)\n",
    "\n",
    "        # Identify continuous sequences\n",
    "        df_cleaned['time_diff'] = df_cleaned['Datetime'].diff().dt.total_seconds()\n",
    "        df_cleaned['is_continuous'] = (df_cleaned['time_diff'].between(59, 61)) | (df_cleaned.index == 0)\n",
    "        df_cleaned['sequence_group'] = (~df_cleaned['is_continuous']).cumsum()\n",
    "\n",
    "        # Determine how many rows to include (10% of the total from time_windows)\n",
    "        limit = int(len(time_windows) * 0.1)\n",
    "\n",
    "        # Select rows up to the limit\n",
    "        cleaned_windows = []\n",
    "        for _, group in df_cleaned.groupby('sequence_group'):\n",
    "            if len(group) >= window_size:\n",
    "                for start_idx in range(0, len(group) - window_size + 1):\n",
    "                    window = group.iloc[start_idx:start_idx + window_size]\n",
    "\n",
    "                    # Flatten the window\n",
    "                    flattened_window = {}\n",
    "                    for column in window.columns:\n",
    "                        if column not in ['Datetime', 'time_diff', 'is_continuous', 'sequence_group']:\n",
    "                            if pd.api.types.is_numeric_dtype(window[column]):\n",
    "                                flattened_window.update({f\"{column}_{i}\": v for i, v in enumerate(window[column].tolist())})\n",
    "                            else:\n",
    "                                flattened_window.update({f\"{column}_0\": window[column].iloc[0]})\n",
    "\n",
    "                    # Add the latest Datetime in the window\n",
    "                    flattened_window[\"Datetime\"] = window['Datetime'].iloc[-1]\n",
    "                    flattened_window[\"main_fault\"] = None  # Always None for cleaned data\n",
    "                    flattened_window[\"seriesnumber\"] = \"806278\"\n",
    "                    cleaned_windows.append(flattened_window)\n",
    "\n",
    "                    # Stop if we've reached the limit\n",
    "                    if len(cleaned_windows) >= limit:\n",
    "                        break\n",
    "            if len(cleaned_windows) >= limit:\n",
    "                break\n",
    "        print(f\"Added {len(cleaned_windows)} rows from cleaned data.\")\n",
    "        time_windows.extend(cleaned_windows)\n",
    "\n",
    "    # Combine all flattened windows into a single DataFrame\n",
    "    all_data = pd.DataFrame(time_windows)\n",
    "\n",
    "    # Step 7: Normalize numeric columns\n",
    "    scaler = MinMaxScaler()\n",
    "    numeric_columns = all_data.select_dtypes(include=['number']).columns\n",
    "    if not numeric_columns.empty:\n",
    "        all_data[numeric_columns] = scaler.fit_transform(all_data[numeric_columns])\n",
    "\n",
    "    # Step 8: Save the prepared data\n",
    "    all_data.to_parquet(output_file, index=False)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Total elapsed time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping model 806031 (excluded)\n",
      "Processing 0 valid groups for model 806272...\n",
      "Skipped groups for model 806272: 0\n",
      "Processing 8 valid groups for model 806017...\n",
      "Skipped groups for model 806017: 6\n",
      "Processing 0 valid groups for model 806029...\n",
      "Skipped groups for model 806029: 0\n",
      "Processing 5 valid groups for model 806020...\n",
      "Skipped groups for model 806020: 4\n",
      "Skipping model 806030 (excluded)\n",
      "Processing 0 valid groups for model 806273...\n",
      "Skipped groups for model 806273: 0\n",
      "Processing 5 valid groups for model 806278...\n",
      "Skipped groups for model 806278: 4\n",
      "Processing 0 valid groups for model 806023...\n",
      "Skipped groups for model 806023: 0\n",
      "Processing 0 valid groups for model 806033...\n",
      "Skipped groups for model 806033: 0\n",
      "Skipping model 806279 (excluded)\n",
      "Processing 0 valid groups for model 806269...\n",
      "Skipped groups for model 806269: 0\n",
      "Processing 0 valid groups for model 808301...\n",
      "Skipped groups for model 808301: 0\n",
      "Processing 0 valid groups for model 806265...\n",
      "Skipped groups for model 806265: 0\n",
      "Skipping model 806026 (excluded)\n",
      "Processing 0 valid groups for model 806281...\n",
      "Skipped groups for model 806281: 0\n",
      "Processing 2 valid groups for model 806274...\n",
      "Skipped groups for model 806274: 1\n",
      "Processing 3 valid groups for model 806018...\n",
      "Skipped groups for model 806018: 12\n",
      "Skipping model 806276 (excluded)\n",
      "Processing 0 valid groups for model 806282...\n",
      "Skipped groups for model 806282: 0\n",
      "Processing 0 valid groups for model 808783...\n",
      "Skipped groups for model 808783: 0\n",
      "Processing 8 valid groups for model 806277...\n",
      "Skipped groups for model 806277: 5\n",
      "Processing 0 valid groups for model 806024...\n",
      "Skipped groups for model 806024: 0\n",
      "Processing 0 valid groups for model 806283...\n",
      "Skipped groups for model 806283: 0\n",
      "Total groups across all models: 63\n",
      "Total skipped groups across all models: 32\n",
      "Processing cleaned data from: /Users/muhammadhussain/Desktop/Data/filter/cleaned_data_806278.parquet\n",
      "Added 6002 rows from cleaned data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/[neuralnetwork]/lib/python3.11/site-packages/sklearn/utils/_array_api.py:695: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/opt/anaconda3/envs/[neuralnetwork]/lib/python3.11/site-packages/sklearn/utils/_array_api.py:712: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 97.72 seconds\n"
     ]
    }
   ],
   "source": [
    "# Angiv sti til dine data og output-fil\n",
    "path = \"/Users/muhammadhussain/Desktop/Data/filter/\"\n",
    "output_file = \"/Users/muhammadhussain/Desktop/Data/filter/finished.parquet\"\n",
    "\n",
    "# Kald funktionen\n",
    "process_parquet_files(path, output_file, window_size=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RTD_0</th>\n",
       "      <th>RTD_1</th>\n",
       "      <th>RTD_2</th>\n",
       "      <th>RTD_3</th>\n",
       "      <th>RTD_4</th>\n",
       "      <th>RTD_5</th>\n",
       "      <th>RTD_6</th>\n",
       "      <th>RTD_7</th>\n",
       "      <th>RTD_8</th>\n",
       "      <th>RTD_9</th>\n",
       "      <th>...</th>\n",
       "      <th>State_26</th>\n",
       "      <th>State_27</th>\n",
       "      <th>State_28</th>\n",
       "      <th>State_29</th>\n",
       "      <th>Type_0</th>\n",
       "      <th>Event_0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>main_fault</th>\n",
       "      <th>seriesnumber</th>\n",
       "      <th>main_fault_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455090</td>\n",
       "      <td>0.463855</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.457831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-03-16 12:29:12</td>\n",
       "      <td>Refrigerant leakage at stage 1</td>\n",
       "      <td>806017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461078</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.457831</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-03-16 12:30:12</td>\n",
       "      <td>Refrigerant leakage at stage 1</td>\n",
       "      <td>806017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.467066</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.457831</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-03-16 12:31:12</td>\n",
       "      <td>Refrigerant leakage at stage 1</td>\n",
       "      <td>806017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.467066</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.457831</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-03-16 12:32:12</td>\n",
       "      <td>Refrigerant leakage at stage 1</td>\n",
       "      <td>806017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.467066</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.457831</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-03-16 12:33:12</td>\n",
       "      <td>Refrigerant leakage at stage 1</td>\n",
       "      <td>806017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66023</th>\n",
       "      <td>0.467066</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.463855</td>\n",
       "      <td>0.451807</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-02-24 10:58:12</td>\n",
       "      <td>None</td>\n",
       "      <td>806278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66024</th>\n",
       "      <td>0.467066</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.463855</td>\n",
       "      <td>0.451807</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-02-24 10:59:12</td>\n",
       "      <td>None</td>\n",
       "      <td>806278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66025</th>\n",
       "      <td>0.467066</td>\n",
       "      <td>0.463855</td>\n",
       "      <td>0.451807</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-02-24 11:00:12</td>\n",
       "      <td>None</td>\n",
       "      <td>806278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66026</th>\n",
       "      <td>0.461078</td>\n",
       "      <td>0.451807</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>0.367470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-02-24 11:01:12</td>\n",
       "      <td>None</td>\n",
       "      <td>806278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66027</th>\n",
       "      <td>0.449102</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>0.367470</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-02-24 11:02:12</td>\n",
       "      <td>None</td>\n",
       "      <td>806278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66028 rows Ã— 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RTD_0     RTD_1     RTD_2     RTD_3     RTD_4     RTD_5     RTD_6  \\\n",
       "0      0.455090  0.463855  0.469880  0.469880  0.469880  0.469880  0.475904   \n",
       "1      0.461078  0.469880  0.469880  0.469880  0.469880  0.475904  0.475904   \n",
       "2      0.467066  0.469880  0.469880  0.469880  0.475904  0.475904  0.469880   \n",
       "3      0.467066  0.469880  0.469880  0.475904  0.475904  0.469880  0.457831   \n",
       "4      0.467066  0.469880  0.475904  0.475904  0.469880  0.457831  0.433735   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "66023  0.467066  0.469880  0.469880  0.463855  0.451807  0.433735  0.397590   \n",
       "66024  0.467066  0.469880  0.463855  0.451807  0.433735  0.397590  0.379518   \n",
       "66025  0.467066  0.463855  0.451807  0.433735  0.397590  0.379518  0.355422   \n",
       "66026  0.461078  0.451807  0.433735  0.397590  0.379518  0.355422  0.343373   \n",
       "66027  0.449102  0.433735  0.397590  0.379518  0.355422  0.343373  0.343373   \n",
       "\n",
       "          RTD_7     RTD_8     RTD_9  ...  State_26  State_27  State_28  \\\n",
       "0      0.475904  0.469880  0.457831  ...  0.157895  0.157895  0.157895   \n",
       "1      0.469880  0.457831  0.433735  ...  0.157895  0.157895  0.157895   \n",
       "2      0.457831  0.433735  0.385542  ...  0.157895  0.157895  0.157895   \n",
       "3      0.433735  0.385542  0.355422  ...  0.157895  0.157895  0.157895   \n",
       "4      0.385542  0.355422  0.343373  ...  0.157895  0.157895  0.157895   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "66023  0.379518  0.355422  0.343373  ...  0.000000  0.000000  0.000000   \n",
       "66024  0.355422  0.343373  0.343373  ...  0.000000  0.000000  0.000000   \n",
       "66025  0.343373  0.343373  0.355422  ...  0.000000  0.000000  0.000000   \n",
       "66026  0.343373  0.355422  0.367470  ...  0.000000  0.000000  0.000000   \n",
       "66027  0.355422  0.367470  0.385542  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "       State_29  Type_0  Event_0            Datetime  \\\n",
       "0      0.157895    None     None 2015-03-16 12:29:12   \n",
       "1      0.157895    None     None 2015-03-16 12:30:12   \n",
       "2      0.157895    None     None 2015-03-16 12:31:12   \n",
       "3      0.157895    None     None 2015-03-16 12:32:12   \n",
       "4      0.157895    None     None 2015-03-16 12:33:12   \n",
       "...         ...     ...      ...                 ...   \n",
       "66023  0.000000    None     None 2013-02-24 10:58:12   \n",
       "66024  0.000000    None     None 2013-02-24 10:59:12   \n",
       "66025  0.000000    None     None 2013-02-24 11:00:12   \n",
       "66026  0.000000    None     None 2013-02-24 11:01:12   \n",
       "66027  0.052632    None     None 2013-02-24 11:02:12   \n",
       "\n",
       "                           main_fault  seriesnumber  main_fault_0  \n",
       "0      Refrigerant leakage at stage 1        806017           NaN  \n",
       "1      Refrigerant leakage at stage 1        806017           NaN  \n",
       "2      Refrigerant leakage at stage 1        806017           NaN  \n",
       "3      Refrigerant leakage at stage 1        806017           NaN  \n",
       "4      Refrigerant leakage at stage 1        806017           NaN  \n",
       "...                               ...           ...           ...  \n",
       "66023                            None        806278           NaN  \n",
       "66024                            None        806278           NaN  \n",
       "66025                            None        806278           NaN  \n",
       "66026                            None        806278           NaN  \n",
       "66027                            None        806278           NaN  \n",
       "\n",
       "[66028 rows x 366 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"/Users/muhammadhussain/Desktop/Data/filter/finished.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[neuralnetwork]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
